{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import DataFetcher class from file heart_data.py\n",
    "import DataFetcher #importing the file DataFetcher.py from the folder data\n",
    "data_fetcher = DataFetcher.DataFetcher(\"C:\\\\Users\\\\kruth\\\\OneDrive\\\\Desktop\\\\Cardiac_Events_ML\\\\preprocessing\\\\final_dataset.csv\")\n",
    "X_train = data_fetcher.get_X_train()\n",
    "X_test = data_fetcher.get_X_test()\n",
    "y_train = data_fetcher.get_y_train()\n",
    "y_test = data_fetcher.get_y_test()\n",
    "features = data_fetcher.get_features()\n",
    "target_names = data_fetcher.get_target_names()\n",
    "X = data_fetcher.get_X()\n",
    "y = data_fetcher.get_y()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard and Soft Voting on 3 Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "lr = joblib.load('joblib_dump\\LRC.pkl')\n",
    "dt = joblib.load('joblib_dump\\DTC.pkl')\n",
    "svm = joblib.load('joblib_dump\\SVM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy of LR  0.65\n",
      "Accuracy of SVM  0.5\n",
      "Accuracy of DT  0.9 \n",
      "\n",
      "Acurracy of hard voting:  0.9\n",
      "Acurracy of soft voting:  0.9333333333333333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier as vc\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "#hard voting\n",
    "#it uses the predicted class labels for majority rule voting\n",
    "voting_clf_hard = vc(estimators=[('lr', lr), ('svm', svm), ('dt', dt)], voting='hard')\n",
    "voting_clf_hard.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_hard = voting_clf_hard.predict(X_test)\n",
    "print(\"Acurracy of LR \", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Accuracy of SVM \", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Accuracy of DT \", accuracy_score(y_test, y_pred_dt),\"\\n\")\n",
    "print(\"Acurracy of hard voting: \", accuracy_score(y_test, y_pred_hard))\n",
    "\n",
    "\n",
    "\n",
    "#soft voting\n",
    "#it uses the predicted class probabilities (predict_proba) for majority rule voting\n",
    "voting_clf_soft = vc(estimators=[('lr', lr), ('svm', svm), ('dt', dt)], voting='soft')\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "y_pred_soft = voting_clf_soft.predict(X_test)\n",
    "print(\"Acurracy of soft voting: \", accuracy_score(y_test, y_pred_soft), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## on more classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "lr = joblib.load('joblib_dump\\LRC.pkl')\n",
    "dt = joblib.load('joblib_dump\\DTC.pkl')\n",
    "svm = joblib.load('joblib_dump\\SVM.pkl')\n",
    "rf = joblib.load('joblib_dump\\RFC.pkl')\n",
    "ab = joblib.load('joblib_dump\\ABC.pkl')\n",
    "gb = joblib.load('joblib_dump\\GBC.pkl')\n",
    "knn = joblib.load('joblib_dump\\KNN.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy of LR  0.65\n",
      "Accuracy of SVM  0.5\n",
      "Accuracy of DT  0.9\n",
      "Accuracy of RF  0.95\n",
      "Accuracy of AB  0.9333333333333333\n",
      "Accuracy of GB  0.9\n",
      "Accuracy of KNN  0.6166666666666667 \n",
      "\n",
      "Acurracy of hard voting:  0.9166666666666666\n",
      "Acurracy of soft voting:  0.8833333333333333 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hard voting\n",
    "#it uses the predicted class labels for majority rule voting\n",
    "voting_clf_hard = vc(estimators=[('lr', lr), ('svm', svm), ('dt', dt), ('rf', rf), ('ab', ab), ('gb', gb), ('knn', knn)], voting='hard')\n",
    "voting_clf_hard.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_ab = ab.predict(X_test)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_pred_hard = voting_clf_hard.predict(X_test)\n",
    "print(\"Acurracy of LR \", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Accuracy of SVM \", accuracy_score(y_test, y_pred_svm))\n",
    "print(\"Accuracy of DT \", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Accuracy of RF \", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Accuracy of AB \", accuracy_score(y_test, y_pred_ab))\n",
    "print(\"Accuracy of GB \", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Accuracy of KNN \", accuracy_score(y_test, y_pred_knn),\"\\n\")\n",
    "\n",
    "print(\"Acurracy of hard voting: \", accuracy_score(y_test, y_pred_hard))\n",
    "\n",
    "\n",
    "\n",
    "#soft voting\n",
    "#it uses the predicted class probabilities (predict_proba) for majority rule voting\n",
    "voting_clf_soft = vc(estimators=[('lr', lr), ('svm', svm), ('dt', dt), ('rf', rf), ('ab', ab), ('gb', gb), ('knn', knn)], voting='soft')\n",
    "voting_clf_soft.fit(X_train, y_train)\n",
    "y_pred_soft = voting_clf_soft.predict(X_test)\n",
    "print(\"Acurracy of soft voting: \", accuracy_score(y_test, y_pred_soft), \"\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging and Pasting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging on Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOb Score:  0.7866108786610879\n",
      "Decision function:  [[0.23684211 0.76315789]\n",
      " [0.54320988 0.45679012]\n",
      " [0.92307692 0.07692308]\n",
      " [0.08860759 0.91139241]\n",
      " [0.275      0.725     ]\n",
      " [0.2        0.8       ]\n",
      " [0.48809524 0.51190476]\n",
      " [0.24050633 0.75949367]\n",
      " [0.73863636 0.26136364]\n",
      " [0.93243243 0.06756757]\n",
      " [0.34146341 0.65853659]\n",
      " [0.90909091 0.09090909]\n",
      " [0.32051282 0.67948718]\n",
      " [0.4939759  0.5060241 ]\n",
      " [0.30263158 0.69736842]\n",
      " [0.34146341 0.65853659]\n",
      " [0.05194805 0.94805195]\n",
      " [0.2987013  0.7012987 ]\n",
      " [0.85185185 0.14814815]\n",
      " [0.41558442 0.58441558]\n",
      " [0.6547619  0.3452381 ]\n",
      " [0.48148148 0.51851852]\n",
      " [0.3375     0.6625    ]\n",
      " [0.59722222 0.40277778]\n",
      " [0.55696203 0.44303797]\n",
      " [0.17283951 0.82716049]\n",
      " [0.04819277 0.95180723]\n",
      " [0.13580247 0.86419753]\n",
      " [0.37837838 0.62162162]\n",
      " [0.58441558 0.41558442]\n",
      " [0.6835443  0.3164557 ]\n",
      " [0.01123596 0.98876404]\n",
      " [0.8313253  0.1686747 ]\n",
      " [0.38961039 0.61038961]\n",
      " [0.33333333 0.66666667]\n",
      " [0.85897436 0.14102564]\n",
      " [0.35897436 0.64102564]\n",
      " [0.52941176 0.47058824]\n",
      " [0.05063291 0.94936709]\n",
      " [0.3875     0.6125    ]\n",
      " [0.22093023 0.77906977]\n",
      " [0.54761905 0.45238095]\n",
      " [0.97560976 0.02439024]\n",
      " [0.11764706 0.88235294]\n",
      " [0.65853659 0.34146341]\n",
      " [0.01190476 0.98809524]\n",
      " [0.37777778 0.62222222]\n",
      " [0.7625     0.2375    ]\n",
      " [0.6375     0.3625    ]\n",
      " [0.8125     0.1875    ]\n",
      " [0.94047619 0.05952381]\n",
      " [0.25316456 0.74683544]\n",
      " [0.90243902 0.09756098]\n",
      " [0.26190476 0.73809524]\n",
      " [0.7875     0.2125    ]\n",
      " [0.03409091 0.96590909]\n",
      " [0.07142857 0.92857143]\n",
      " [0.34146341 0.65853659]\n",
      " [0.79452055 0.20547945]\n",
      " [0.30864198 0.69135802]\n",
      " [0.62195122 0.37804878]\n",
      " [0.84615385 0.15384615]\n",
      " [0.3373494  0.6626506 ]\n",
      " [0.60759494 0.39240506]\n",
      " [0.74025974 0.25974026]\n",
      " [0.20481928 0.79518072]\n",
      " [0.33333333 0.66666667]\n",
      " [0.86746988 0.13253012]\n",
      " [0.77922078 0.22077922]\n",
      " [0.62195122 0.37804878]\n",
      " [0.43373494 0.56626506]\n",
      " [0.90697674 0.09302326]\n",
      " [0.13253012 0.86746988]\n",
      " [0.2625     0.7375    ]\n",
      " [0.35294118 0.64705882]\n",
      " [0.85714286 0.14285714]\n",
      " [0.82142857 0.17857143]\n",
      " [0.03797468 0.96202532]\n",
      " [0.25581395 0.74418605]\n",
      " [0.8875     0.1125    ]\n",
      " [0.15       0.85      ]\n",
      " [0.3625     0.6375    ]\n",
      " [0.40963855 0.59036145]\n",
      " [0.69411765 0.30588235]\n",
      " [0.03614458 0.96385542]\n",
      " [0.01149425 0.98850575]\n",
      " [0.15294118 0.84705882]\n",
      " [0.40243902 0.59756098]\n",
      " [0.65384615 0.34615385]\n",
      " [0.06896552 0.93103448]\n",
      " [0.72839506 0.27160494]\n",
      " [0.6        0.4       ]\n",
      " [0.29411765 0.70588235]\n",
      " [0.51315789 0.48684211]\n",
      " [0.8974359  0.1025641 ]\n",
      " [0.26829268 0.73170732]\n",
      " [0.86746988 0.13253012]\n",
      " [0.60240964 0.39759036]\n",
      " [0.79268293 0.20731707]\n",
      " [0.14814815 0.85185185]\n",
      " [0.02409639 0.97590361]\n",
      " [0.22077922 0.77922078]\n",
      " [0.41176471 0.58823529]\n",
      " [0.5375     0.4625    ]\n",
      " [0.93975904 0.06024096]\n",
      " [0.31168831 0.68831169]\n",
      " [0.38554217 0.61445783]\n",
      " [0.51851852 0.48148148]\n",
      " [0.66666667 0.33333333]\n",
      " [0.51764706 0.48235294]\n",
      " [0.82278481 0.17721519]\n",
      " [0.04878049 0.95121951]\n",
      " [0.20238095 0.79761905]\n",
      " [0.8625     0.1375    ]\n",
      " [0.34090909 0.65909091]\n",
      " [0.11764706 0.88235294]\n",
      " [0.3625     0.6375    ]\n",
      " [0.0125     0.9875    ]\n",
      " [0.48235294 0.51764706]\n",
      " [0.46987952 0.53012048]\n",
      " [0.57777778 0.42222222]\n",
      " [0.71052632 0.28947368]\n",
      " [0.8        0.2       ]\n",
      " [0.90123457 0.09876543]\n",
      " [0.77108434 0.22891566]\n",
      " [0.61904762 0.38095238]\n",
      " [0.34210526 0.65789474]\n",
      " [0.06329114 0.93670886]\n",
      " [0.3373494  0.6626506 ]\n",
      " [0.51388889 0.48611111]\n",
      " [0.93975904 0.06024096]\n",
      " [0.75294118 0.24705882]\n",
      " [0.92857143 0.07142857]\n",
      " [0.2        0.8       ]\n",
      " [0.39772727 0.60227273]\n",
      " [0.58441558 0.41558442]\n",
      " [0.24137931 0.75862069]\n",
      " [0.45679012 0.54320988]\n",
      " [0.55421687 0.44578313]\n",
      " [0.1097561  0.8902439 ]\n",
      " [0.02352941 0.97647059]\n",
      " [0.87012987 0.12987013]\n",
      " [0.2625     0.7375    ]\n",
      " [0.69879518 0.30120482]\n",
      " [0.71428571 0.28571429]\n",
      " [0.825      0.175     ]\n",
      " [0.10344828 0.89655172]\n",
      " [0.3164557  0.6835443 ]\n",
      " [0.51851852 0.48148148]\n",
      " [0.28       0.72      ]\n",
      " [0.31168831 0.68831169]\n",
      " [0.27380952 0.72619048]\n",
      " [0.25301205 0.74698795]\n",
      " [0.10588235 0.89411765]\n",
      " [0.21176471 0.78823529]\n",
      " [0.79012346 0.20987654]\n",
      " [0.04878049 0.95121951]\n",
      " [0.37333333 0.62666667]\n",
      " [0.12820513 0.87179487]\n",
      " [0.44155844 0.55844156]\n",
      " [0.94186047 0.05813953]\n",
      " [0.08988764 0.91011236]\n",
      " [0.39726027 0.60273973]\n",
      " [0.64197531 0.35802469]\n",
      " [0.37349398 0.62650602]\n",
      " [0.125      0.875     ]\n",
      " [0.69411765 0.30588235]\n",
      " [0.83116883 0.16883117]\n",
      " [0.36144578 0.63855422]\n",
      " [0.53012048 0.46987952]\n",
      " [0.53488372 0.46511628]\n",
      " [0.85       0.15      ]\n",
      " [0.98701299 0.01298701]\n",
      " [0.18666667 0.81333333]\n",
      " [0.04878049 0.95121951]\n",
      " [0.73170732 0.26829268]\n",
      " [0.77333333 0.22666667]\n",
      " [0.0617284  0.9382716 ]\n",
      " [0.86666667 0.13333333]\n",
      " [0.56410256 0.43589744]\n",
      " [0.11904762 0.88095238]\n",
      " [0.43037975 0.56962025]\n",
      " [0.72619048 0.27380952]\n",
      " [0.24691358 0.75308642]\n",
      " [0.82352941 0.17647059]\n",
      " [0.31707317 0.68292683]\n",
      " [0.65       0.35      ]\n",
      " [0.10344828 0.89655172]\n",
      " [0.55696203 0.44303797]\n",
      " [0.17721519 0.82278481]\n",
      " [0.05263158 0.94736842]\n",
      " [0.38271605 0.61728395]\n",
      " [0.07594937 0.92405063]\n",
      " [0.02597403 0.97402597]\n",
      " [0.22093023 0.77906977]\n",
      " [0.86419753 0.13580247]\n",
      " [0.03529412 0.96470588]\n",
      " [0.92405063 0.07594937]\n",
      " [0.46835443 0.53164557]\n",
      " [0.28378378 0.71621622]\n",
      " [0.74390244 0.25609756]\n",
      " [0.87804878 0.12195122]\n",
      " [0.45454545 0.54545455]\n",
      " [0.525      0.475     ]\n",
      " [0.91860465 0.08139535]\n",
      " [0.7654321  0.2345679 ]\n",
      " [0.25609756 0.74390244]\n",
      " [0.63095238 0.36904762]\n",
      " [0.88607595 0.11392405]\n",
      " [0.18421053 0.81578947]\n",
      " [0.10666667 0.89333333]\n",
      " [0.73809524 0.26190476]\n",
      " [0.94186047 0.05813953]\n",
      " [0.86666667 0.13333333]\n",
      " [0.41463415 0.58536585]\n",
      " [0.22077922 0.77922078]\n",
      " [0.08860759 0.91139241]\n",
      " [0.16666667 0.83333333]\n",
      " [0.6627907  0.3372093 ]\n",
      " [0.98666667 0.01333333]\n",
      " [0.08139535 0.91860465]\n",
      " [0.2        0.8       ]\n",
      " [0.61445783 0.38554217]\n",
      " [1.         0.        ]\n",
      " [0.46666667 0.53333333]\n",
      " [0.56818182 0.43181818]\n",
      " [0.03658537 0.96341463]\n",
      " [0.51315789 0.48684211]\n",
      " [0.24137931 0.75862069]\n",
      " [0.09459459 0.90540541]\n",
      " [0.50617284 0.49382716]\n",
      " [0.10126582 0.89873418]\n",
      " [0.32941176 0.67058824]\n",
      " [0.57692308 0.42307692]\n",
      " [0.76190476 0.23809524]\n",
      " [0.37662338 0.62337662]\n",
      " [0.42682927 0.57317073]\n",
      " [0.73076923 0.26923077]\n",
      " [0.2804878  0.7195122 ]]\n",
      "Acurracy of bagging:  0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kruth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   2 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   2 out of  16 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier as bc\n",
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#bagging (bootstrap = True)\n",
    "#it uses soft voting by default, (predict_proba scores of each instance for each class of every DT in the forest is considered)\n",
    "#RANDOM PATCHES: Sampling both training instances and features is called the Random Patches method.\n",
    "#Sampling features results in even more predictor diversity, trading a bit more bias for a lower variance.\n",
    "#RANDOM SUBSPACES: Sampling features with all training instances is called the Random Subspaces method.\n",
    "bagging_clf = bc(base_estimator=dtc(), \n",
    "                n_estimators=100,  #number of trees in the forest\n",
    "                max_samples=50, #number of instances to draw from X_train to train each Decision Tree\n",
    "                max_features=1.0, #number of features to draw from X_train to train each Decision Tree\n",
    "                bootstrap=True, #whether samples are drawn with replacement\n",
    "                bootstrap_features=False, #whether features are drawn with replacement\n",
    "                oob_score= True, #whether to use out-of-bag samples to estimate the generalization accuracy\n",
    "                n_jobs=-1,\n",
    "                verbose= 1\n",
    ")\n",
    "\n",
    "bagging_clf.fit(X_train, y_train)\n",
    "print(\"OOb Score: \", bagging_clf.oob_score_) #gives the mean accuracy on the out-of-bag samples (generalization accuracy)\n",
    "print(\"Decision function: \", bagging_clf.oob_decision_function_) #gives class probabilities for each instance in the out-of-bag set\n",
    "y_pred_bagging = bagging_clf.predict(X_test)\n",
    "print(\"Acurracy of bagging: \", accuracy_score(y_test, y_pred_bagging))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pasting with Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy of pasting:  0.8666666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kruth\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   2 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=16)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done   2 out of  16 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done  16 out of  16 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#pasting (bootstrap=False)\n",
    "#it uses hard voting by default, (the class with the highest number of votes is predicted)\n",
    "pasting_clf = bc(base_estimator=dtc(),\n",
    "                n_estimators=100,  #number of trees in the forest\n",
    "                max_samples=50, #number of instances to draw from X_train to train each Decision Tree\n",
    "                max_features=1.0, #number of features to draw from X_train to train each Decision Tree\n",
    "                bootstrap=False, #whether samples are drawn with replacement\n",
    "                bootstrap_features=False, #whether features are drawn with replacement\n",
    "                n_jobs=-1,\n",
    "                verbose= 1\n",
    ")\n",
    "\n",
    "pasting_clf.fit(X_train, y_train)\n",
    "y_pred_pasting = pasting_clf.predict(X_test)\n",
    "print(\"Acurracy of pasting: \", accuracy_score(y_test, y_pred_pasting))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done 418 tasks      | elapsed:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 768 tasks      | elapsed:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=16)]: Using backend ThreadingBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=16)]: Done  18 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 168 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurracy of Random Forest:  0.95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=16)]: Done 418 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 768 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=16)]: Done 1000 out of 1000 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "#Random Forest is an ensemble of Decision Trees, generally\n",
    "#trained via the bagging method (or sometimes pasting), typically with max_samples\n",
    "#set to the size of the training set.\n",
    "#The Random Forest algorithm introduces extra randomness when growing trees;\n",
    "#instead of searching for the very best feature when splitting a node, it\n",
    "#searches for the best feature among a random subset of features.\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "rf_clf = rfc(n_estimators=1000,\n",
    "            max_depth=2,\n",
    "            #max_features=2, #if 2, accuracy = 0.95\n",
    "            #max_samples=50,\n",
    "            #max_leaf_nodes=4,\n",
    "            bootstrap=True, #bagging\n",
    "            min_samples_leaf=8, \n",
    "            min_samples_split=4,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbose=1\n",
    ")\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(\"Acurracy of Random Forest: \", accuracy_score(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
