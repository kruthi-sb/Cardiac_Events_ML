{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries:\n",
    "import sklearn as sk, pandas as pd, numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the preprocessed full dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the csv file and store it as a DataFrame\n",
    "full_dset = pd.read_csv(\"C:\\\\Users\\\\kruth\\\\OneDrive\\\\Desktop\\\\Cardiac_Events_ML\\\\preprocessing\\\\final_dataset.csv\")\n",
    "#drop the inddex column\n",
    "full_dset.drop([\"index\"], axis = 1, inplace = True)\n",
    "#print first 5 rows of the dataset\n",
    "full_dset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target variable and feature columns separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code snippet will separate the target variable from the features of the dataset.\n",
    "y_s = full_dset[\"output\"] #y holds target variable as a pandas Series.It has 300 rows.\n",
    "y_df = pd.DataFrame(y_s)\n",
    "X_df = full_dset.drop(\"output\", axis=1, inplace = False)# X holds only the 13 feature columns by droping output column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_df.values\n",
    "y = y_df.values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA SPLIT: Stratified sampling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kruth\\AppData\\Local\\Temp\\ipykernel_19560\\1052886726.py:19: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True) #converts to 1D array.\n"
     ]
    }
   ],
   "source": [
    "#Stratified sampling is a method that ensures that the class distribution in the training and testing sets is representative of the overall dataset. \n",
    "#It is used when the dataset is imbalanced, meaning that one class has many more samples than the other.\n",
    "#Prevoiusly, in EDA, we saw that the diseased class had 136 instances whereas the non-diseased class had 163 instances. So, it is slightly imbalanced.\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import column_or_1d\n",
    "\n",
    "\n",
    "# initialize the StratifiedShuffleSplit object\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "#n_splits is 1 => splits the dataset once(one pair of testing and training dataset)\n",
    "#test_size is 0.2 => test set includes 20% of dataset. The rest 80% is for training dataset.\n",
    "#random_state is 42 => controls the randomness of the training and testing indices produced. 42 renders the same pair of sets everytime I run the code.\n",
    "\n",
    "# fit the Scaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X) #Scaling the values such that the mean is 0 and std deviation is 1.\n",
    "\n",
    "y = column_or_1d(y, warn=True) #converts to 1D array.\n",
    "\n",
    "# iterate over the 1 split\n",
    "for train_index, test_index in sss.split(X, y): #returns lists which contain the indicies.\n",
    "    X_train, X_test = X[train_index], X[test_index] #feature dataset in numpy array\n",
    "    y_train, y_test = y[train_index], y[test_index] #target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.79      0.83        24\n",
      "           1       0.87      0.92      0.89        36\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.87      0.85      0.86        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# train the model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test dataset\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# evaluate the model's performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ', accuracy)\n",
    "\n",
    "# get the precision, recall, and f1-score\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8666666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        24\n",
      "           1       0.91      0.86      0.89        36\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.86      0.87      0.86        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the model\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred1 = rf_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred1))\n",
    "# get the precision, recall, and f1-score\n",
    "cr1 = classification_report(y_test, y_pred1)\n",
    "print(cr1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        24\n",
      "           1       0.91      0.86      0.89        36\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.86      0.87      0.86        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize the model\n",
    "dt_clf = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "cr1 = classification_report(y_test, y_pred1)\n",
    "print(cr1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84        24\n",
      "           1       0.91      0.86      0.89        36\n",
      "\n",
      "    accuracy                           0.87        60\n",
      "   macro avg       0.86      0.87      0.86        60\n",
      "weighted avg       0.87      0.87      0.87        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize the model\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn_clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "cr1 = classification_report(y_test, y_pred1)\n",
    "print(cr1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89        24\n",
      "           1       0.90      0.97      0.93        36\n",
      "\n",
      "    accuracy                           0.92        60\n",
      "   macro avg       0.92      0.90      0.91        60\n",
      "weighted avg       0.92      0.92      0.92        60\n",
      "\n",
      "Accuracy: 0.9166666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the model\n",
    "svm = SVC(kernel='linear', C=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88        24\n",
      "           1       0.92      0.92      0.92        36\n",
      "\n",
      "    accuracy                           0.90        60\n",
      "   macro avg       0.90      0.90      0.90        60\n",
      "weighted avg       0.90      0.90      0.90        60\n",
      "\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Fit the model to the training data\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.79      0.76        24\n",
      "           1       0.85      0.81      0.83        36\n",
      "\n",
      "    accuracy                           0.80        60\n",
      "   macro avg       0.79      0.80      0.79        60\n",
      "weighted avg       0.80      0.80      0.80        60\n",
      "\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Initialize the model\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Fit the model to the training data\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = gbc.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.87, Recall: 0.75, F1-Score: 0.81\n",
      "Accuracy: 0.7833333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Initialize the AdaBoostClassifier\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "# Calculate precision, recall, and f1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f'Precision: {precision:.2f}, Recall: {recall:.2f}, F1-Score: {f1:.2f}')\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0058379c129e4629443e4d8323bec08f6392318539cc5f99608b31d35e1b8ca4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
